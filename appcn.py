import os
import sys
import gradio as gr
from src.gradio_demo import SadTalker
from pyngrok import ngrok

try:
    import webui  # in webui
    in_webui = True
except:
    in_webui = False

# åˆ‡æ¢éŸ³é¢‘æ–‡ä»¶çš„å¯è§æ€§
def toggle_audio_file(choice):
    if choice == False:
        return gr.update(visible=True), gr.update(visible=False)
    else:
        return gr.update(visible=False), gr.update(visible=True)

# åˆ‡æ¢è§†é¢‘å‚è€ƒæ–‡ä»¶çš„å€¼çš„å¯è§æ€§
def ref_video_fn(path_of_ref_video):
    if path_of_ref_video is not None:
        return gr.update(value=True)
    else:
        return gr.update(value=False)

# åˆ›å»ºSadTalkerå®ä¾‹ï¼Œåˆå§‹åŒ–æ¨¡å‹
def sadtalker_demo(
    checkpoint_path="checkpoints", config_path="src/config", warpfn=None
):
    sad_talker = SadTalker(checkpoint_path, config_path, lazy_load=True)

    # åˆ›å»ºGradioç•Œé¢
    with gr.Blocks(analytics_enabled=False) as sadtalker_interface:
        gr.Markdown(
            "<div align='center'> <h2> ğŸ˜­ SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation (CVPR 2023) </span> </h2> \
                    <a style='font-size:18px;color: #efefef' href='https://arxiv.org/abs/2211.12194'>Arxiv</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \
                    <a style='font-size:18px;color: #efefef' href='https://sadtalker.github.io'>Homepage</a>  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \
                     <a style='font-size:18px;color: #efefef' href='https://github.com/Winfredy/SadTalker'> Github </div>"
        )

        # æºå›¾ç‰‡
        with gr.Row().style(equal_height=False):
            with gr.Column(variant="panel"):
                with gr.Tabs(elem_id="sadtalker_source_image"):
                    with gr.TabItem("ä¸Šä¼ å›¾ç‰‡"):
                        with gr.Row():
                            source_image = gr.Image(
                                label="æºå›¾ç‰‡",
                                source="upload",
                                type="filepath",
                                elem_id="img2img_image",
                            ).style(width=512)

        # é©±åŠ¨éŸ³é¢‘
        with gr.Tabs(elem_id="sadtalker_driven_audio"):
            with gr.TabItem("ä¸Šä¼ æˆ–ä½¿ç”¨TTS"):
                with gr.Column(variant="panel"):
                    driven_audio = gr.Audio(
                        label="è¾“å…¥éŸ³é¢‘", source="upload", type="filepath"
                    )

                    # æ–‡å­—è½¬è¯­éŸ³
                    if sys.platform != "win32" and not in_webui:
                        from src.utils.text2speech import TTSTalker

                        tts_talker = TTSTalker()
                        with gr.Column(variant="panel"):
                            input_text = gr.Textbox(
                                label="é€šè¿‡æ–‡æœ¬ç”ŸæˆéŸ³é¢‘",
                                lines=5,
                                placeholder="è¯·è¾“å…¥æ–‡æœ¬ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ @Coqui.ai TTS ç”ŸæˆéŸ³é¢‘ã€‚",
                            )
                            tts = gr.Button(
                                "ç”ŸæˆéŸ³é¢‘",
                                elem_id="sadtalker_audio_generate",
                                variant="primary",
                            )
                            tts.click(
                                fn=tts_talker.test,
                                inputs=[input_text],
                                outputs=[driven_audio],
                            )

        # è®¾ç½®é€‰é¡¹
        with gr.Column(variant="panel"):
            with gr.Tabs(elem_id="sadtalker_checkbox"):
                with gr.TabItem("è®¾ç½®"):
                    gr.Markdown(
                        "éœ€è¦å¸®åŠ©ï¼Ÿè¯·è®¿é—®æˆ‘ä»¬çš„[æœ€ä½³å®è·µé¡µ](https://github.com/OpenTalker/SadTalker/blob/main/docs/best_practice.md)äº†è§£æ›´å¤šè¯¦ç»†ä¿¡æ¯"
                    )
                    with gr.Column(variant="panel"):
                        pose_style = gr.Slider(
                            minimum=0,
                            maximum=46,
                            step=1,
                            label="å§¿åŠ¿é£æ ¼",
                            value=0,
                        )  #
                        size_of_image = gr.Radio(
                            [256, 512],
                            value=256,
                            label="äººè„¸æ¨¡å‹åˆ†è¾¨ç‡",
                            info="ä½¿ç”¨256/512æ¨¡å‹ï¼Ÿ",
                        )  #
                        preprocess_type = gr.Radio(
                            ["è£å‰ª", "è°ƒæ•´å¤§å°", "å®Œæ•´", "æ‰©å±•è£å‰ª", "æ‰©å±•å®Œæ•´"],
                            value="è£å‰ª",
                            label="é¢„å¤„ç†",
                            info="å¦‚ä½•å¤„ç†è¾“å…¥å›¾åƒï¼Ÿ",
                        )
                        is_still_mode = gr.Checkbox(
                            label="é™æ€æ¨¡å¼ï¼ˆå‡å°‘æ‰‹éƒ¨åŠ¨ä½œï¼Œé€‚ç”¨äºé¢„å¤„ç†é€‰é¡¹`å®Œæ•´`ï¼‰"
                        )
                        batch_size = gr.Slider(
                            label="ç”Ÿæˆä¸­çš„æ‰¹å¤„ç†å¤§å°",
                            step=1,
                            maximum=10,
                            value=2,
                        )
                        enhancer = gr.Checkbox(label="GFPGANä½œä¸ºé¢éƒ¨å¢å¼ºå™¨")
                        submit = gr.Button(
                            "ç”Ÿæˆ",
                            elem_id="sadtalker_generate",
                            variant="primary",
                        )

        # åˆ›å»ºç”Ÿæˆçš„è§†é¢‘
        with gr.Tabs(elem_id="sadtalker_genearted"):
            gen_video = gr.Video(label="ç”Ÿæˆçš„è§†é¢‘", format="mp4").style(
                width=256
            )

        # æ ¹æ®warpfnæ˜¯å¦å­˜åœ¨è®¾ç½®ç”ŸæˆæŒ‰é’®çš„å›è°ƒå‡½æ•°
        if warpfn:
            submit.click(
                fn=warpfn(sad_talker.test),
                inputs=[
                    source_image,
                    driven_audio,
                    preprocess_type,
                    is_still_mode,
                    enhancer,
                    batch_size,
                    size_of_image,
                    pose_style,
                ],
                outputs=[gen_video],
            )
        else:
            submit.click(
                fn=sad_talker.test,
                inputs=[
                    source_image,
                    driven_audio,
                    preprocess_type,
                    is_still_mode,
                    enhancer,
                    batch_size,
                    size_of_image,
                    pose_style,
                ],
                outputs=[gen_video],
            )

    return sadtalker_interface

# ä¸»å‡½æ•°
if __name__ == "__main__":
    ngrok.set_auth_token("2T2uKcVHFVIQj5JxFkarQQi3Lb1_4QzQC5bUULf5PZLSBHySz")

    # åˆ›å»ºä¸€ä¸ªå¤–é“¾
    public_url = ngrok.connect("localhost:7860")
    print("ç½‘ç«™é“¾æ¥:", public_url)

    demo = sadtalker_demo()
    demo.queue()
    demo.launch()
